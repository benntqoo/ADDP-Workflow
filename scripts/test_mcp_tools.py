#!/usr/bin/env python3
"""
MCP å·¥å…·æµ‹è¯•è„šæœ¬
================

æµ‹è¯•æ‰€æœ‰ MCP å·¥å…·çš„åŠŸèƒ½ï¼ŒéªŒè¯ Universal AI Coding Framework çš„å®Œæ•´æ€§ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/test_mcp_tools.py              # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    python scripts/test_mcp_tools.py --tool init  # æµ‹è¯•ç‰¹å®šå·¥å…·
    python scripts/test_mcp_tools.py --verbose    # è¯¦ç»†è¾“å‡º
"""

import asyncio
import argparse
import json
import sys
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.mcp_server.tools.project_tools import ProjectInitializer
from src.mcp_server.tools.query_optimizer import QueryOptimizer
from src.mcp_server.tools.workflow_manager import WorkflowManager
from src.mcp_server.tools.sync_manager import SyncManager

class MCPToolsTester:
    """MCP å·¥å…·æµ‹è¯•å™¨"""

    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.test_results = {}
        self.temp_dir = None

    async def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹ MCP å·¥å…·æµ‹è¯•")
        print("=" * 50)

        # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç¯å¢ƒ
        self.temp_dir = Path(tempfile.mkdtemp(prefix="mcp_test_"))
        original_cwd = Path.cwd()

        try:
            # åˆ‡æ¢åˆ°æµ‹è¯•ç›®å½•
            import os
            os.chdir(self.temp_dir)

            # è¿è¡Œå„é¡¹æµ‹è¯•
            await self.test_project_initialization()
            await self.test_query_optimization()
            await self.test_workflow_management()
            await self.test_sync_management()

            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            self.generate_test_report()

        finally:
            # æ¢å¤åŸç›®å½•
            os.chdir(original_cwd)
            # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
            if self.temp_dir and self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)

        return self.test_results

    async def test_project_initialization(self):
        """æµ‹è¯•é¡¹ç›®åˆå§‹åŒ–åŠŸèƒ½"""
        print("\nğŸ—ï¸  æµ‹è¯•é¡¹ç›®åˆå§‹åŒ–...")

        test_name = "project_initialization"
        try:
            initializer = ProjectInitializer()

            # æµ‹è¯•è‡ªåŠ¨æ£€æµ‹
            result = await initializer.initialize_structure(
                project_type="test",
                project_name="mcp_test_project",
                framework="auto-detect"
            )

            # éªŒè¯ç»“æœ
            checks = []
            checks.append(("åˆå§‹åŒ–æˆåŠŸ", result.get("success", False)))
            checks.append(("ç›®å½•åˆ›å»º", result.get("directories_created", 0) > 0))
            checks.append(("æ–‡ä»¶ç”Ÿæˆ", result.get("files_created", 0) > 0))
            checks.append(("é…ç½®åˆ›å»º", result.get("configs_created", 0) > 0))

            # éªŒè¯ç›®å½•ç»“æ„
            addp_path = Path(".addp")
            checks.append(("ADDPç›®å½•å­˜åœ¨", addp_path.exists()))

            if addp_path.exists():
                expected_dirs = ["specifications", "workflows", "memory", "queries", "gates", "sync"]
                for dir_name in expected_dirs:
                    checks.append((f"{dir_name}ç›®å½•", (addp_path / dir_name).exists()))

            # éªŒè¯å…³é”®æ–‡ä»¶
            key_files = [
                ".addp/metadata.json",
                ".addp/README.md",
                ".addp/specifications/templates/prd_template.md",
                ".addp/configs/mcp/server_config.json"
            ]

            for file_path in key_files:
                checks.append((f"æ–‡ä»¶: {Path(file_path).name}", Path(file_path).exists()))

            self.test_results[test_name] = {
                "status": "passed" if all(check[1] for check in checks) else "failed",
                "checks": checks,
                "details": result
            }

            if self.verbose:
                for check_name, passed in checks:
                    status = "âœ…" if passed else "âŒ"
                    print(f"  {status} {check_name}")

        except Exception as e:
            self.test_results[test_name] = {
                "status": "error",
                "error": str(e),
                "checks": []
            }
            print(f"âŒ é¡¹ç›®åˆå§‹åŒ–æµ‹è¯•å¤±è´¥: {e}")

    async def test_query_optimization(self):
        """æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–åŠŸèƒ½"""
        print("\nğŸ§  æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–...")

        test_name = "query_optimization"
        try:
            optimizer = QueryOptimizer()

            # æµ‹è¯•ç”¨ä¾‹
            test_cases = [
                {
                    "name": "åŸºç¡€ä¼˜åŒ–",
                    "input": "ä¼˜åŒ–æ€§èƒ½",
                    "level": "basic",
                    "context": ""
                },
                {
                    "name": "æ™ºèƒ½ä¼˜åŒ–",
                    "input": "å®ç°ç”¨æˆ·ç™»å½•",
                    "level": "smart",
                    "context": "React å‰ç«¯é¡¹ç›®"
                },
                {
                    "name": "è¯¦ç»†ä¼˜åŒ–",
                    "input": "é‡æ„ä»£ç ",
                    "level": "detailed",
                    "context": "Python Flask åç«¯"
                }
            ]

            checks = []
            for test_case in test_cases:
                try:
                    result = await optimizer.optimize(
                        test_case["input"],
                        test_case["context"],
                        test_case["level"]
                    )

                    # éªŒè¯ä¼˜åŒ–ç»“æœ
                    required_fields = ["optimized_query", "improvements", "suggestions", "confidence"]
                    case_passed = all(field in result for field in required_fields)

                    # éªŒè¯ä¼˜åŒ–è´¨é‡
                    if case_passed:
                        optimized_length = len(result.get("optimized_query", ""))
                        original_length = len(test_case["input"])
                        improvement_ratio = optimized_length / max(original_length, 1)

                        # ä¼˜åŒ–åçš„æŸ¥è¯¢åº”è¯¥æ›´è¯¦ç»† (é€šå¸¸æ›´é•¿)
                        case_passed = improvement_ratio > 0.8

                    checks.append((test_case["name"], case_passed))

                except Exception as e:
                    checks.append((test_case["name"], False))
                    if self.verbose:
                        print(f"  âŒ {test_case['name']} å¤±è´¥: {e}")

            # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
            try:
                # ç¬¬äºŒæ¬¡è°ƒç”¨ç›¸åŒæŸ¥è¯¢ï¼Œåº”è¯¥ä½¿ç”¨ç¼“å­˜
                cached_result = await optimizer.optimize("ä¼˜åŒ–æ€§èƒ½", "", "basic")
                cache_working = cached_result.get("from_cache", False)
                checks.append(("ç¼“å­˜åŠŸèƒ½", cache_working))
            except:
                checks.append(("ç¼“å­˜åŠŸèƒ½", False))

            # æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
            try:
                stats = await optimizer.get_optimization_stats()
                stats_working = "total_optimizations" in stats
                checks.append(("ç»Ÿè®¡åŠŸèƒ½", stats_working))
            except:
                checks.append(("ç»Ÿè®¡åŠŸèƒ½", False))

            self.test_results[test_name] = {
                "status": "passed" if all(check[1] for check in checks) else "failed",
                "checks": checks,
                "total_tests": len(checks)
            }

            if self.verbose:
                for check_name, passed in checks:
                    status = "âœ…" if passed else "âŒ"
                    print(f"  {status} {check_name}")

        except Exception as e:
            self.test_results[test_name] = {
                "status": "error",
                "error": str(e),
                "checks": []
            }
            print(f"âŒ æŸ¥è¯¢ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")

    async def test_workflow_management(self):
        """æµ‹è¯•å·¥ä½œæµç®¡ç†åŠŸèƒ½"""
        print("\nâš¡ æµ‹è¯• ADDP å·¥ä½œæµ...")

        test_name = "workflow_management"
        try:
            workflow_manager = WorkflowManager()

            # æµ‹è¯•å„ä¸ªé˜¶æ®µ
            phases = ["analysis", "design", "development", "persistence"]
            checks = []

            # æ¨¡æ‹Ÿå®Œæ•´çš„å·¥ä½œæµå¾ªç¯
            previous_output = ""
            for phase in phases:
                try:
                    result = await workflow_manager.execute_phase(
                        phase=phase,
                        specification="æµ‹è¯•éœ€æ±‚ï¼šå®ç°ç”¨æˆ·æ³¨å†ŒåŠŸèƒ½",
                        previous_phase_output=previous_output
                    )

                    # éªŒè¯é˜¶æ®µæ‰§è¡Œç»“æœ
                    phase_passed = all([
                        result.get("phase") == phase,
                        result.get("status") == "completed",
                        "output" in result,
                        "quality_gates" in result
                    ])

                    checks.append((f"{phase}é˜¶æ®µ", phase_passed))

                    # å‡†å¤‡ä¸‹ä¸€é˜¶æ®µçš„è¾“å…¥
                    if phase_passed:
                        previous_output = json.dumps(result.get("output", {}))

                except Exception as e:
                    checks.append((f"{phase}é˜¶æ®µ", False))
                    if self.verbose:
                        print(f"  âŒ {phase} é˜¶æ®µå¤±è´¥: {e}")

            # æµ‹è¯•å·¥ä½œæµçŠ¶æ€
            try:
                status = await workflow_manager.get_workflow_status()
                status_working = "current_phase" in status or "status" in status
                checks.append(("çŠ¶æ€æŸ¥è¯¢", status_working))
            except:
                checks.append(("çŠ¶æ€æŸ¥è¯¢", False))

            self.test_results[test_name] = {
                "status": "passed" if all(check[1] for check in checks) else "failed",
                "checks": checks,
                "phases_tested": len(phases)
            }

            if self.verbose:
                for check_name, passed in checks:
                    status = "âœ…" if passed else "âŒ"
                    print(f"  {status} {check_name}")

        except Exception as e:
            self.test_results[test_name] = {
                "status": "error",
                "error": str(e),
                "checks": []
            }
            print(f"âŒ å·¥ä½œæµç®¡ç†æµ‹è¯•å¤±è´¥: {e}")

    async def test_sync_management(self):
        """æµ‹è¯•è·¨å·¥å…·åŒæ­¥åŠŸèƒ½"""
        print("\nğŸ”„ æµ‹è¯•è·¨å·¥å…·åŒæ­¥...")

        test_name = "sync_management"
        try:
            sync_manager = SyncManager()

            # æµ‹è¯•ç”¨ä¾‹
            test_tools = ["claude", "gemini", "cursor"]
            checks = []

            # æµ‹è¯•çŠ¶æ€ä¿å­˜å’ŒåŠ è½½
            for tool in test_tools:
                try:
                    # ä¿å­˜æµ‹è¯•çŠ¶æ€
                    test_state = {
                        "session_id": f"test_{tool}",
                        "timestamp": "2024-01-01T00:00:00",
                        "data": {"test": True}
                    }

                    save_result = await sync_manager.sync_state(
                        action="save",
                        tool_name=tool,
                        state_data=json.dumps(test_state)
                    )

                    save_success = save_result.get("success", False)
                    checks.append((f"{tool}ä¿å­˜", save_success))

                    if save_success:
                        # æµ‹è¯•çŠ¶æ€åŠ è½½
                        load_result = await sync_manager.sync_state(
                            action="load",
                            tool_name=tool
                        )

                        load_success = load_result.get("success", False)
                        checks.append((f"{tool}åŠ è½½", load_success))

                except Exception as e:
                    checks.append((f"{tool}ä¿å­˜", False))
                    checks.append((f"{tool}åŠ è½½", False))
                    if self.verbose:
                        print(f"  âŒ {tool} åŒæ­¥å¤±è´¥: {e}")

            # æµ‹è¯•å…¨å·¥å…·åŒæ­¥
            try:
                sync_all_result = await sync_manager.sync_state(action="sync_all")
                sync_all_success = sync_all_result.get("success", False)
                checks.append(("å…¨å·¥å…·åŒæ­¥", sync_all_success))
            except:
                checks.append(("å…¨å·¥å…·åŒæ­¥", False))

            # æµ‹è¯•åŒæ­¥çŠ¶æ€æŸ¥è¯¢
            try:
                status = await sync_manager.get_sync_status()
                status_working = "supported_tools" in status and "tool_status" in status
                checks.append(("çŠ¶æ€æŸ¥è¯¢", status_working))
            except:
                checks.append(("çŠ¶æ€æŸ¥è¯¢", False))

            self.test_results[test_name] = {
                "status": "passed" if all(check[1] for check in checks) else "failed",
                "checks": checks,
                "tools_tested": len(test_tools)
            }

            if self.verbose:
                for check_name, passed in checks:
                    status = "âœ…" if passed else "âŒ"
                    print(f"  {status} {check_name}")

        except Exception as e:
            self.test_results[test_name] = {
                "status": "error",
                "error": str(e),
                "checks": []
            }
            print(f"âŒ è·¨å·¥å…·åŒæ­¥æµ‹è¯•å¤±è´¥: {e}")

    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š æµ‹è¯•æŠ¥å‘Š")
        print("=" * 50)

        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values()
                          if result["status"] == "passed")
        failed_tests = sum(1 for result in self.test_results.values()
                          if result["status"] == "failed")
        error_tests = sum(1 for result in self.test_results.values()
                         if result["status"] == "error")

        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"âœ… é€šè¿‡: {passed_tests}")
        print(f"âŒ å¤±è´¥: {failed_tests}")
        print(f"ğŸ’¥ é”™è¯¯: {error_tests}")
        print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")

        # è¯¦ç»†ç»“æœ
        for test_name, result in self.test_results.items():
            status_icon = {"passed": "âœ…", "failed": "âŒ", "error": "ğŸ’¥"}[result["status"]]
            print(f"\n{status_icon} {test_name}:")

            if result["status"] == "error":
                print(f"   é”™è¯¯: {result.get('error', 'Unknown error')}")
            else:
                checks = result.get("checks", [])
                for check_name, passed in checks:
                    check_icon = "âœ…" if passed else "âŒ"
                    print(f"   {check_icon} {check_name}")

        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        if hasattr(self, 'temp_dir') and self.temp_dir:
            report_file = Path.cwd() / f"mcp_test_report_{asyncio.get_event_loop().time():.0f}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    async def test_specific_tool(self, tool_name: str):
        """æµ‹è¯•ç‰¹å®šå·¥å…·"""
        print(f"ğŸ”§ æµ‹è¯•ç‰¹å®šå·¥å…·: {tool_name}")

        if tool_name == "init":
            await self.test_project_initialization()
        elif tool_name == "optimize":
            await self.test_query_optimization()
        elif tool_name == "workflow":
            await self.test_workflow_management()
        elif tool_name == "sync":
            await self.test_sync_management()
        else:
            print(f"âŒ æœªçŸ¥å·¥å…·: {tool_name}")
            return

        self.generate_test_report()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="MCP å·¥å…·æµ‹è¯•è„šæœ¬")
    parser.add_argument("--tool", type=str,
                       choices=["init", "optimize", "workflow", "sync"],
                       help="æµ‹è¯•ç‰¹å®šå·¥å…·")
    parser.add_argument("--verbose", action="store_true",
                       help="è¯¦ç»†è¾“å‡º")

    args = parser.parse_args()

    tester = MCPToolsTester(verbose=args.verbose)

    try:
        if args.tool:
            asyncio.run(tester.test_specific_tool(args.tool))
        else:
            results = asyncio.run(tester.run_all_tests())

            # æ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®é€€å‡ºç 
            if all(result["status"] == "passed" for result in results.values()):
                print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
                sys.exit(0)
            else:
                print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æŠ¥å‘Š")
                sys.exit(1)

    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·å–æ¶ˆ")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()