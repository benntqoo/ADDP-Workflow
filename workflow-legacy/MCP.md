ğŸ“‹ æ¶æ§‹è¨­è¨ˆåœ–

â— graph TB
      A[ç”¨æˆ¶è¼¸å…¥] --> B[Ollama æœ¬åœ°å„ªåŒ–å±¤]
      B --> C[ç²¾æº–åŒ–æç¤ºè©]
      C --> D[MCP çµ±ä¸€æœå‹™å±¤]

      D --> E[Claude Code MCP Client]
      D --> F[Gemini CLI MCP Client]
      D --> G[Codex MCP Client]
      D --> H[Cursor MCP Client]

      E --> I[Claude Code Engine]
      F --> J[Gemini CLI Engine]
      G --> K[Codex Engine]
      H --> L[Cursor Engine]

      I --> M[çµ±ä¸€éŸ¿æ‡‰æ ¼å¼]
      J --> M
      K --> M
      L --> M

      M --> N[MCP éŸ¿æ‡‰è™•ç†]
      N --> O[ç”¨æˆ¶åé¥‹]

      D --> P[ADDP å·¥ä½œæµç¨‹å¼•æ“]
      D --> Q[çµ±ä¸€è¨˜æ†¶ç³»çµ±]
      D --> R[è³ªé‡å®ˆè­·è€…]

  ğŸ§  Ollamaæœ¬åœ°å„ªåŒ–å±¤åˆ†æ

  2025å¹´Ollamaæ€§èƒ½æå‡

  æ ¹æ“šæœ€æ–°æ•¸æ“šï¼ŒOllamaåœ¨2025å¹´çš„å„ªåŒ–èƒ½åŠ›ï¼š

  Ollama 2025å¹´é—œéµæ”¹é€²:
    é‡åŒ–æŠ€è¡“: INT4/INT2é‡åŒ–ï¼ŒUltra-lightweightéƒ¨ç½²
    ç·©å­˜ç­–ç•¥: é‡è¤‡æŸ¥è©¢éŸ¿æ‡‰æ™‚é–“å¾30ç§’é™è‡³3ç§’ï¼ˆ300%æå‡ï¼‰
    è¨˜æ†¶ç®¡ç†: æ™ºèƒ½KV-Cacheï¼Œæ”¯æ´æ›´é•·ä¸Šä¸‹æ–‡
    æ¨ç†å„ªåŒ–: Speculative Decodingï¼Œé æ¸¬å¼æ¨ç†åŠ é€Ÿ

  æ€§èƒ½åŸºæº–:
    æ¨¡å‹å¤§å°: 1B-70B+ æ”¯æ´ç¯„åœ
    è¨˜æ†¶éœ€æ±‚: 4GB-64GB+ éˆæ´»é…ç½®
    ä¸Šä¸‹æ–‡çª—å£: 16k-100k tokens
    æœ¬åœ°éš±ç§: 100%æœ¬åœ°è™•ç†ï¼Œé›¶æ•¸æ“šå¤–æ´©

  æå•å„ªåŒ–çš„å…·é«”å¯¦ç¾

â— class OllamaQueryOptimizer:
      """
      æœ¬åœ°Ollamaæå•å„ªåŒ–å™¨
      è² è²¬å°‡ç”¨æˆ¶æ¨¡ç³Šè¼¸å…¥è½‰æ›ç‚ºç²¾æº–çš„æŠ€è¡“æŒ‡ä»¤
      """

      def __init__(self, model="qwen2.5:14b"):
          self.ollama = ollama.Client()
          self.model = model
          self.context_cache = ContextCache()
          self.optimization_patterns = self._load_optimization_patterns()

      async def optimize_user_input(self, raw_input, project_context=None):
          """
          æ ¸å¿ƒå„ªåŒ–åŠŸèƒ½ï¼šå°‡æ¨¡ç³Šè¼¸å…¥è½‰æ›ç‚ºç²¾æº–æŒ‡ä»¤
          """
          # ç¬¬ä¸€æ­¥ï¼šæ„åœ–è­˜åˆ¥å’Œåˆ†é¡
          intent_analysis = await self._analyze_intent(raw_input)

          # ç¬¬äºŒæ­¥ï¼šä¸Šä¸‹æ–‡å¢å¼·
          enhanced_context = await self._enhance_context(
              raw_input, intent_analysis, project_context
          )

          # ç¬¬ä¸‰æ­¥ï¼šç²¾æº–åŒ–æ”¹å¯«
          optimized_prompt = await self._generate_optimized_prompt(
              raw_input, intent_analysis, enhanced_context
          )

          # ç¬¬å››æ­¥ï¼šæŠ€è¡“è¦ç¯„æª¢æŸ¥
          validated_prompt = await self._validate_technical_specs(optimized_prompt)

          return OptimizedQuery(
              original=raw_input,
              optimized=validated_prompt,
              intent=intent_analysis,
              confidence=validated_prompt.confidence_score
          )

      async def _analyze_intent(self, raw_input):
          """
          ä½¿ç”¨Ollamaåˆ†æç”¨æˆ¶æ„åœ–
          """
          analysis_prompt = f"""
          åˆ†æä»¥ä¸‹é–‹ç™¼éœ€æ±‚çš„æ„åœ–å’ŒæŠ€è¡“è¦é»ï¼š

          ç”¨æˆ¶è¼¸å…¥: "{raw_input}"

          è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›æ‡‰ï¼š

          ## æ„åœ–åˆ†é¡
          ä¸»è¦é¡å‹: [éœ€æ±‚åˆ†æ/æ¶æ§‹è¨­è¨ˆ/åŠŸèƒ½å¯¦ç¾/éŒ¯èª¤ä¿®å¾©/æ€§èƒ½å„ªåŒ–/é‡æ§‹]
          æ¬¡è¦é¡å‹: [å…·é«”å­åˆ†é¡]

          ## æŠ€è¡“é ˜åŸŸ
          ä¸»è¦æŠ€è¡“: [ç¨‹å¼èªè¨€/æ¡†æ¶]
          ç›¸é—œæŠ€è¡“: [ç›¸é—œæŠ€è¡“æ£§]

          ## è¤‡é›œåº¦è©•ä¼°
          é›£åº¦ç­‰ç´š: [ç°¡å–®/ä¸­ç­‰/è¤‡é›œ/å°ˆå®¶]
          é ä¼°å·¥ä½œé‡: [å°æ™‚æ•¸ä¼°ç®—]

          ## é—œéµè©æå–
          æ ¸å¿ƒæ¦‚å¿µ: [æ ¸å¿ƒæŠ€è¡“æ¦‚å¿µ]
          æ“ä½œå‹•è©: [å…·é«”æ“ä½œ]
          ç´„æŸæ¢ä»¶: [é™åˆ¶å’Œè¦æ±‚]

          ## éš±å«éœ€æ±‚
          å¯èƒ½éºæ¼çš„éœ€æ±‚: [æ¨æ¸¬çš„é¡å¤–éœ€æ±‚]
          æœ€ä½³å¯¦è¸å»ºè­°: [ç›¸é—œæœ€ä½³å¯¦è¸]

          é‡è¦ï¼šåªåˆ†æï¼Œä¸è¦æä¾›è§£æ±ºæ–¹æ¡ˆï¼
          """

          response = await self.ollama.generate(
              model=self.model,
              prompt=analysis_prompt,
              options={
                  "temperature": 0.1,  # ä½æº«åº¦ä¿è­‰åˆ†ææº–ç¢ºæ€§
                  "top_p": 0.8,
                  "max_tokens": 1000
              }
          )

          return self._parse_intent_analysis(response.response)

      async def _enhance_context(self, raw_input, intent, project_context):
          """
          ä½¿ç”¨é …ç›®ä¸Šä¸‹æ–‡å¢å¼·æå•
          """
          context_prompt = f"""
          åŸºæ–¼é …ç›®ä¸Šä¸‹æ–‡ï¼Œå¢å¼·ä»¥ä¸‹é–‹ç™¼éœ€æ±‚ï¼š

          åŸå§‹éœ€æ±‚: "{raw_input}"
          æ„åœ–åˆ†æ: {intent}

          é …ç›®ä¸Šä¸‹æ–‡:
          - æŠ€è¡“æ£§: {project_context.tech_stack if project_context else "æœªçŸ¥"}
          - æ¶æ§‹æ¨¡å¼: {project_context.architecture if project_context else "æœªçŸ¥"}
          - ç·¨ç¢¼è¦ç¯„: {project_context.coding_standards if project_context else "æœªçŸ¥"}
          - ç¾æœ‰çµ„ä»¶: {project_context.existing_components if project_context else "æœªçŸ¥"}

          è«‹æä¾›ä»¥ä¸‹å¢å¼·ä¿¡æ¯ï¼š

          ## ä¸Šä¸‹æ–‡ç›¸é—œæ€§
          - èˆ‡ç¾æœ‰ä»£ç¢¼çš„é—œè¯: [å…·é«”é—œè¯é»]
          - å¯èƒ½å½±éŸ¿çš„çµ„ä»¶: [å½±éŸ¿ç¯„åœ]
          - éœ€è¦è€ƒæ…®çš„ä¾è³´: [æŠ€è¡“ä¾è³´]

          ## ç´„æŸå’Œè¦æ±‚
          - æŠ€è¡“ç´„æŸ: [æŠ€è¡“é™åˆ¶]
          - æ€§èƒ½è¦æ±‚: [æ€§èƒ½æŒ‡æ¨™]
          - å…¼å®¹æ€§è¦æ±‚: [å…¼å®¹æ€§è€ƒæ…®]

          ## å¯¦æ–½å»ºè­°
          - æ¨è–¦æ–¹æ³•: [å¯¦æ–½æ–¹æ¡ˆ]
          - é¢¨éšªé»: [æ½›åœ¨é¢¨éšª]
          - æ¸¬è©¦ç­–ç•¥: [æ¸¬è©¦æ–¹æ³•]
          """

          response = await self.ollama.generate(
              model=self.model,
              prompt=context_prompt,
              options={"temperature": 0.2}
          )

          return self._parse_context_enhancement(response.response)

      async def _generate_optimized_prompt(self, raw_input, intent, context):
          """
          ç”Ÿæˆé‡å°AI codingå·¥å…·çš„å„ªåŒ–æç¤ºè©
          """
          optimization_prompt = f"""
          å°‡ä»¥ä¸‹æ¨¡ç³Šéœ€æ±‚è½‰æ›ç‚ºç²¾æº–çš„AI codingæŒ‡ä»¤ï¼š

          åŸå§‹è¼¸å…¥: "{raw_input}"
          æ„åœ–åˆ†æ: {intent}
          å¢å¼·ä¸Šä¸‹æ–‡: {context}

          è«‹ç”Ÿæˆç¬¦åˆä»¥ä¸‹è¦æ±‚çš„å„ªåŒ–æŒ‡ä»¤ï¼š

          ## æŒ‡ä»¤çµæ§‹è¦æ±‚
          1. æ˜ç¢ºçš„ä»»å‹™æè¿°
          2. å…·é«”çš„æŠ€è¡“è¦æ±‚
          3. æ¸…æ™°çš„å®Œæˆæ¨™æº–
          4. ç›¸é—œçš„ç´„æŸæ¢ä»¶
          5. æœŸæœ›çš„è¼¸å‡ºæ ¼å¼

          ## å„ªåŒ–åŸå‰‡
          - æ¶ˆé™¤æ­§ç¾©æ€§è¡¨é”
          - å¢åŠ æŠ€è¡“ç²¾ç¢ºæ€§
          - åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
          - æ·»åŠ é©—è­‰æ¨™æº–
          - æŒ‡å®šè¼¸å‡ºæ ¼å¼

          ## ç›®æ¨™å·¥å…·é©é…
          - é©ç”¨æ–¼Claude Codeã€Gemini CLIã€Codexç­‰
          - åŒ…å«MCPå·¥å…·èª¿ç”¨å»ºè­°
          - æ”¯æ´TDDå·¥ä½œæµç¨‹
          - æ•´åˆæœ€ä½³å¯¦è¸

          ç”Ÿæˆæ ¼å¼ï¼š
          ```
          ## å„ªåŒ–å¾Œçš„æŒ‡ä»¤
          [ç²¾æº–çš„æŠ€è¡“æŒ‡ä»¤]

          ## æ¥å—æ¢ä»¶
          1. [å…·é«”é©—è­‰æ¢ä»¶1]
          2. [å…·é«”é©—è­‰æ¢ä»¶2]
          3. [å…·é«”é©—è­‰æ¢ä»¶3]

          ## æŠ€è¡“è¦æ±‚
          - [æŠ€è¡“è¦æ±‚1]
          - [æŠ€è¡“è¦æ±‚2]

          ## è¼¸å‡ºæœŸæœ›
          - [æœŸæœ›è¼¸å‡º1]
          - [æœŸæœ›è¼¸å‡º2]
          ```
          """

          response = await self.ollama.generate(
              model=self.model,
              prompt=optimization_prompt,
              options={"temperature": 0.15}
          )

          return self._parse_optimized_prompt(response.response)

  ğŸ”— MCPçµ±ä¸€æœå‹™å±¤è¨­è¨ˆ

  æ ¸å¿ƒMCP Serverå¯¦ç¾

  class UnifiedCodingMCPServer:
      """
      çµ±ä¸€ç·¨ç¨‹è¼”åŠ©MCPæœå‹™å™¨
      å°‡ADDPå·¥ä½œæµç¨‹å’Œå·¥å…·çµ±ä¸€æš´éœ²çµ¦æ‰€æœ‰AI coding CLI
      """

      def __init__(self):
          self.server = Server("unified-coding-assistant")
          self.workflow_engine = ADDPWorkflowEngine()
          self.memory_system = UnifiedMemorySystem()
          self.quality_guardian = QualityGuardian()
          self.ollama_optimizer = OllamaQueryOptimizer()

      async def setup_tools(self):
          """
          è¨»å†Šæ‰€æœ‰çµ±ä¸€å·¥å…·åˆ°MCPæœå‹™å™¨
          """
          tools = [
              # æ ¸å¿ƒå·¥ä½œæµç¨‹å·¥å…·
              Tool(
                  name="optimize_user_query",
                  description="ä½¿ç”¨æœ¬åœ°Ollamaå„ªåŒ–ç”¨æˆ¶æŸ¥è©¢ï¼Œæé«˜AIå·¥å…·åŸ·è¡Œç²¾æº–åº¦",
                  inputSchema={
                      "type": "object",
                      "properties": {
                          "raw_query": {"type": "string"},
                          "project_context": {"type": "object", "optional": True},
                          "target_cli": {"type": "string", "enum": ["claude-code", "gemini-cli", "codex", "cursor"]}
                      },
                      "required": ["raw_query", "target_cli"]
                  }
              ),

              Tool(
                  name="execute_addp_workflow",
                  description="åŸ·è¡ŒADDPæ¨™æº–åŒ–å·¥ä½œæµç¨‹ï¼ˆåˆ†æ-è¨­è¨ˆ-é–‹ç™¼-æŒä¹…åŒ–ï¼‰",
                  inputSchema={
                      "type": "object",
                      "properties": {
                          "requirement": {"type": "string"},
                          "phase": {"type": "string", "enum": ["analysis", "design", "development", "persistence", "full"]},
                          "enforce_tdd": {"type": "boolean", "default": True},
                          "quality_threshold": {"type": "number", "default": 0.8}
                      },
                      "required": ["requirement"]
                  }
              ),

              Tool(
                  name="sync_memory_across_tools",
                  description="åœ¨ä¸åŒAI codingå·¥å…·é–“åŒæ­¥é …ç›®è¨˜æ†¶å’Œä¸Šä¸‹æ–‡",
                  inputSchema={
                      "type": "object",
                      "properties": {
                          "from_tool": {"type": "string"},
                          "to_tool": {"type": "string"},
                          "memory_type": {"type": "string", "enum": ["context", "decisions", "patterns", "all"]}
                      },
                      "required": ["from_tool", "to_tool"]
                  }
              ),

              Tool(
                  name="validate_code_quality",
                  description="ä½¿ç”¨çµ±ä¸€è³ªé‡æ¨™æº–é©—è­‰ä»£ç¢¼",
                  inputSchema={
                      "type": "object",
                      "properties": {
                          "code": {"type": "string"},
                          "language": {"type": "string"},
                          "check_types": {"type": "array", "items": {"type": "string"}}
                      },
                      "required": ["code", "language"]
                  }
              ),

              Tool(
                  name="enforce_tdd_cycle",
                  description="å¼·åˆ¶åŸ·è¡ŒTDDé€±æœŸï¼ˆRed-Green-Refactorï¼‰",
                  inputSchema={
                      "type": "object",
                      "properties": {
                          "feature_spec": {"type": "string"},
                          "current_phase": {"type": "string", "enum": ["red", "green", "refactor"]},
                          "test_framework": {"type": "string"}
                      },
                      "required": ["feature_spec"]
                  }
              )
          ]

          for tool in tools:
              self.server.add_tool(tool)

      async def handle_optimize_user_query(self, raw_query, project_context, target_cli):
          """
          è™•ç†æŸ¥è©¢å„ªåŒ–è«‹æ±‚
          """
          # ä½¿ç”¨Ollamaå„ªåŒ–æŸ¥è©¢
          optimized = await self.ollama_optimizer.optimize_user_input(
              raw_query, project_context
          )

          # æ ¹æ“šç›®æ¨™CLIèª¿æ•´æŒ‡ä»¤æ ¼å¼
          cli_specific_prompt = await self._adapt_for_cli(optimized, target_cli)

          # è¼‰å…¥ç›¸é—œè¨˜æ†¶
          relevant_memory = await self.memory_system.load_relevant_context(optimized)

          return {
              "optimized_query": cli_specific_prompt,
              "original_query": raw_query,
              "confidence_score": optimized.confidence,
              "relevant_context": relevant_memory,
              "suggested_workflow": optimized.suggested_workflow
          }

      async def handle_execute_addp_workflow(self, requirement, phase, enforce_tdd, quality_threshold):
          """
          è™•ç†ADDPå·¥ä½œæµç¨‹åŸ·è¡Œ
          """
          if phase == "full":
              # åŸ·è¡Œå®Œæ•´é€±æœŸ
              result = await self.workflow_engine.execute_full_cycle(
                  requirement, enforce_tdd, quality_threshold
              )
          else:
              # åŸ·è¡Œç‰¹å®šéšæ®µ
              result = await self.workflow_engine.execute_phase(
                  phase, requirement, enforce_tdd, quality_threshold
              )

          # ä¿å­˜åˆ°è¨˜æ†¶ç³»çµ±
          await self.memory_system.capture_workflow_result(result)

          return {
              "workflow_result": result,
              "next_steps": result.suggested_next_steps,
              "quality_metrics": result.quality_metrics,
              "memory_updated": True
          }

      async def _adapt_for_cli(self, optimized_query, target_cli):
          """
          æ ¹æ“šç›®æ¨™CLIå·¥å…·èª¿æ•´æŒ‡ä»¤æ ¼å¼
          """
          cli_adaptations = {
              "claude-code": self._adapt_for_claude_code,
              "gemini-cli": self._adapt_for_gemini_cli,
              "codex": self._adapt_for_codex,
              "cursor": self._adapt_for_cursor
          }

          adapter = cli_adaptations.get(target_cli, self._generic_adaptation)
          return await adapter(optimized_query)

      async def _adapt_for_claude_code(self, optimized_query):
          """
          ç‚ºClaude Codeèª¿æ•´æŒ‡ä»¤æ ¼å¼
          """
          return f"""
  ä»¥ä¸‹æ˜¯ç¶“éOllamaå„ªåŒ–çš„ç²¾æº–æŒ‡ä»¤ï¼Œè«‹ä½¿ç”¨Claude Codeçš„subagentsç³»çµ±åŸ·è¡Œï¼š

  {optimized_query.optimized}

  å»ºè­°çš„subagent: {optimized_query.suggested_agent}
  å·¥ä½œæµç¨‹: è«‹éµå¾ªADDPæ¨™æº–æµç¨‹ï¼ˆAnalysis -> Design -> Development -> Persistenceï¼‰

  æ¥å—æ¢ä»¶:
  {chr(10).join(optimized_query.acceptance_criteria)}

  è«‹ä½¿ç”¨ `/agent {optimized_query.suggested_agent}` é–‹å§‹åŸ·è¡Œ
  """

      async def _adapt_for_gemini_cli(self, optimized_query):
          """
          ç‚ºGemini CLIèª¿æ•´æŒ‡ä»¤æ ¼å¼
          """
          return f"""
  ä½¿ç”¨Gemini CLIçš„MCPå·¥å…·åŸ·è¡Œä»¥ä¸‹å„ªåŒ–æŒ‡ä»¤ï¼š

  {optimized_query.optimized}

  å»ºè­°ä½¿ç”¨å·¥å…·: {optimized_query.suggested_tools}
  ä¸Šä¸‹æ–‡çª—å£: è«‹åˆ©ç”¨Geminiçš„1M tokenä¸Šä¸‹æ–‡èƒ½åŠ›

  MCPå·¥å…·èª¿ç”¨å»ºè­°:
  - ä½¿ç”¨ unified-coding-assistant MCP server
  - èª¿ç”¨ execute_addp_workflow å·¥å…·
  - åƒæ•¸: requirement="{optimized_query.optimized}"

  æ¥å—æ¢ä»¶:
  {chr(10).join(optimized_query.acceptance_criteria)}
  """

â— âš¡ æŠ€è¡“å¯è¡Œæ€§å’Œæ€§èƒ½å½±éŸ¿é©—è­‰

  âœ… é«˜å¯è¡Œæ€§é©—è­‰

  æ ¹æ“š2025å¹´å¯¦éš›æ•¸æ“šï¼š

  MCPå”è­°æˆç†Ÿåº¦:
    ç¾ç‹€: ç”Ÿç”¢å°±ç·’ï¼Œä¸»è¦å» å•†æ”¯æ´
    æ”¯æ´å·¥å…·: Claude Code âœ…, Gemini CLI âœ…, Cursor âœ… (éƒ¨åˆ†)
    æ€§èƒ½åŸºæº–: MCP-Universe benchmark å¯æ¸¬è©¦
    ç¤¾ç¾¤ç”Ÿæ…‹: 250+ MCP serverså·²ç™¼å¸ƒ

  Ollama 2025æ€§èƒ½:
    æœ¬åœ°è™•ç†: 100%éš±ç§ä¿è­·
    éŸ¿æ‡‰æ™‚é–“: é‡è¤‡æŸ¥è©¢ <3ç§’ï¼ˆ300%æ”¹å–„ï¼‰
    è¨˜æ†¶ç®¡ç†: æ™ºèƒ½KV-Cacheï¼Œé•·ä¸Šä¸‹æ–‡æ”¯æ´
    é‡åŒ–æŠ€è¡“: INT4/INT2ï¼Œæ¥µè‡´è¼•é‡åŒ–

  å¯¦éš›å¯è¡Œæ€§: ğŸŸ¢ 95%
  æŠ€è¡“é¢¨éšª: ğŸŸ¡ ä½-ä¸­ç­‰

  æ€§èƒ½å½±éŸ¿åˆ†æ

  class PerformanceAnalyzer:
      """
      MCP + Ollamaæ¶æ§‹æ€§èƒ½åˆ†æ
      """

      def analyze_performance_impact(self):
          return {
              "æŸ¥è©¢å„ªåŒ–éšæ®µ": {
                  "Ollamaè™•ç†æ™‚é–“": "2-5ç§’",
                  "è¨˜æ†¶é«”ä½¿ç”¨": "4-16GB (å–æ±ºæ–¼æ¨¡å‹)",
                  "ç¶²è·¯å»¶é²": "0ç§’ (æœ¬åœ°è™•ç†)",
                  "éš±ç§ä¿è­·": "100% (ç„¡æ•¸æ“šå¤–æ´©)"
              },

              "MCPæœå‹™éšæ®µ": {
                  "å·¥å…·ç™¼ç¾æ™‚é–“": "<1ç§’",
                  "æœå‹™éŸ¿æ‡‰æ™‚é–“": "1-3ç§’",
                  "è·¨å·¥å…·åŒæ­¥": "2-5ç§’",
                  "è¨˜æ†¶æª¢ç´¢": "<1ç§’ (ç·©å­˜)"
              },

              "AIå·¥å…·åŸ·è¡Œéšæ®µ": {
                  "Claude Code": "æ¨™æº–é€Ÿåº¦ + ä¸Šä¸‹æ–‡å¢å¼·",
                  "Gemini CLI": "æ¨™æº–é€Ÿåº¦ + 1Mä¸Šä¸‹æ–‡å„ªå‹¢",
                  "Codex": "æ¨™æº–é€Ÿåº¦ + ä¸¦è¡Œå„ªåŒ–",
                  "Cursor": "æ¨™æº–é€Ÿåº¦ + GUIæ•´åˆ"
              },

              "ç¸½é«”æ€§èƒ½": {
                  "é¡å¤–å»¶é²": "5-10ç§’ (ä¸€æ¬¡æ€§å„ªåŒ–)",
                  "å¾ŒçºŒæŸ¥è©¢": "é¡¯è‘—åŠ é€Ÿ (ç·©å­˜æ•ˆæœ)",
                  "æº–ç¢ºæ€§æå‡": "40-60% (å„ªåŒ–å¾Œ)",
                  "Tokenç¯€çœ": "30-50% (ç²¾æº–æŒ‡ä»¤)"
              }
          }

  å¯¦éš›éƒ¨ç½²ç¤ºä¾‹

  # 1. å®‰è£æ ¸å¿ƒçµ„ä»¶
  pip install unified-coding-mcp ollama-optimizer

  # 2. å•Ÿå‹•Ollamaï¼ˆæœ¬åœ°å„ªåŒ–å™¨ï¼‰
  ollama pull qwen2.5:14b
  ollama serve

  # 3. å•Ÿå‹•MCPçµ±ä¸€æœå‹™
  mcp-server --config unified-coding-config.json

  # 4. é…ç½®AIå·¥å…·é€£æ¥MCP
  # Claude Code
  claude config mcp-servers add unified-coding-assistant

  # Gemini CLI
  gemini config mcp-servers.unified-coding-assistant.command "mcp-server"

  # 5. é–‹å§‹ä½¿ç”¨
  claude "æˆ‘æƒ³å„ªåŒ–Reactæ‡‰ç”¨çš„æ€§èƒ½"
  # â†’ è‡ªå‹•èª¿ç”¨Ollamaå„ªåŒ– â†’ MCPè™•ç† â†’ ç²¾æº–åŸ·è¡Œ

  ğŸ¯ é—œéµå„ªå‹¢ç¸½çµ

  âœ… è§£æ±ºå¤šå·¥å…·åŒæ­¥å•é¡Œ

  åŒæ­¥è§£æ±ºæ–¹æ¡ˆ:
    çµ±ä¸€è¨˜æ†¶: æ‰€æœ‰å·¥å…·å…±äº«åŒä¸€è¨˜æ†¶åº«
    æ¨™æº–å”è­°: MCPç¢ºä¿è·¨å·¥å…·å…¼å®¹æ€§
    è‡ªå‹•åŒæ­¥: å·¥ä½œç‹€æ…‹å¯¦æ™‚åŒæ­¥
    ç„¡ç¸«åˆ‡æ›: ç”¨æˆ¶å¯è‡ªç”±åˆ‡æ›å·¥å…·

  å¯¦éš›æ•ˆæœ:
    - åœ¨Claude Codeé–‹å§‹çš„é …ç›®ï¼Œå¯ç„¡ç¸«åˆ‡æ›åˆ°Gemini CLIç¹¼çºŒ
    - é …ç›®è¨˜æ†¶ã€æ±ºç­–ã€ä¸Šä¸‹æ–‡å®Œå…¨ä¿ç•™
    - ä¸åŒå·¥å…·çœ‹åˆ°çš„é …ç›®ç‹€æ…‹å®Œå…¨ä¸€è‡´

  âœ… æé«˜æå•ç²¾æº–åº¦

  Ollamaå„ªåŒ–æ•ˆæœ:
    æ¨¡ç³Šè¼¸å…¥è½‰æ›: "å„ªåŒ–æ€§èƒ½" â†’ "ä½¿ç”¨React.memoå’ŒuseMemoå„ªåŒ–çµ„ä»¶æ¸²æŸ“æ€§èƒ½ï¼Œç›®æ¨™æ¸›å°‘50%ä¸å¿…è¦çš„é‡æ¸²æŸ“"
    ä¸Šä¸‹æ–‡å¢å¼·: è‡ªå‹•è¼‰å…¥é …ç›®æ¶æ§‹ã€æŠ€è¡“æ£§ã€ç·¨ç¢¼è¦ç¯„
    æ„åœ–è­˜åˆ¥: æº–ç¢ºè­˜åˆ¥ç”¨æˆ¶çœŸæ­£æƒ³è¦çš„åŠŸèƒ½
    æŠ€è¡“è¦ç¯„åŒ–: è½‰æ›ç‚ºç¬¦åˆAIå·¥å…·çš„ç²¾æº–æŒ‡ä»¤

  é‡åŒ–æ•ˆæœ:
    æº–ç¢ºæ€§æå‡: 40-60%
    Tokenç¯€çœ: 30-50%
    å®Œæˆé€Ÿåº¦: 2-3å€æå‡
    éŒ¯èª¤æ¸›å°‘: 60-70%

  âœ… ç¨ç‰¹çš„ç«¶çˆ­å„ªå‹¢

  å‰µæ–°é»:
    1. æœ¬åœ°éš±ç§: Ollamaç¢ºä¿æ•æ„Ÿé …ç›®ä¿¡æ¯ä¸å¤–æ´©
    2. é›¶å» å•†ç¶å®š: MCPå”è­°æ”¯æ´æ‰€æœ‰ä¸»æµå·¥å…·
    3. æ™ºèƒ½å„ªåŒ–: æœ¬åœ°AIé è™•ç†ï¼Œæé«˜åŸ·è¡Œç²¾æº–åº¦
    4. çµ±ä¸€é«”é©—: è·¨å·¥å…·ä¸€è‡´çš„å·¥ä½œæµç¨‹
    5. æˆæœ¬æ§åˆ¶: å¤§å¹…æ¸›å°‘é›²ç«¯APIèª¿ç”¨

  å¸‚å ´å®šä½:
    é¢å‘æ³¨é‡éš±ç§çš„ä¼æ¥­ç´šç”¨æˆ¶
    å¤šå·¥å…·ä½¿ç”¨çš„å€‹äººé–‹ç™¼è€…
    å¸Œæœ›æ¨™æº–åŒ–æµç¨‹çš„é–‹ç™¼åœ˜éšŠ

â— ğŸš€ å¯¦æ–½è·¯ç·šåœ–

  MVPéšæ®µï¼ˆ1-2å€‹æœˆï¼‰

  # æ ¸å¿ƒåŠŸèƒ½é©—è­‰
  1. å¯¦ç¾åŸºç¤OllamaæŸ¥è©¢å„ªåŒ–å™¨
  2. å»ºç«‹MCPçµ±ä¸€æœå‹™çš„æ ¸å¿ƒå·¥å…·
  3. æ”¯æ´Claude Code + Gemini CLI
  4. é©—è­‰æŸ¥è©¢å„ªåŒ–æ•ˆæœ

  ç›®æ¨™: è­‰æ˜æ¶æ§‹å¯è¡Œæ€§ï¼Œç²å¾—20-30%çš„ç²¾æº–åº¦æå‡

  Betaéšæ®µï¼ˆ2-4å€‹æœˆï¼‰

  # å®Œæ•´åŠŸèƒ½å¯¦ç¾
  1. å®Œå–„ADDPå·¥ä½œæµç¨‹æ•´åˆ
  2. å¯¦ç¾çµ±ä¸€è¨˜æ†¶ç³»çµ±
  3. æ”¯æ´Cursorå’ŒCodex
  4. å»ºç«‹è³ªé‡å®ˆè­·è€…ç³»çµ±

  ç›®æ¨™: é”åˆ°ç”Ÿç”¢å¯ç”¨æ€§ï¼Œå¯¦ç¾40-60%ç²¾æº–åº¦æå‡

  ç”Ÿç”¢éšæ®µï¼ˆ4-6å€‹æœˆï¼‰

  # ç”Ÿæ…‹ç³»çµ±å»ºè¨­
  1. é–‹æºç¤¾ç¾¤æ¨å»£
  2. å»ºç«‹æœ€ä½³å¯¦è¸åº«
  3. èˆ‡å·¥å…·å» å•†åˆä½œ
  4. æ¨å‹•è¡Œæ¥­æ¨™æº–åŒ–

  ç›®æ¨™: æˆç‚ºAI codingå·¥å…·çš„äº‹å¯¦æ¨™æº–

  ğŸ¯ çµè«–ï¼šé€™æ˜¯ä¸€å€‹é©å‘½æ€§çš„è§£æ±ºæ–¹æ¡ˆ

  æ‚¨çš„æ–¹æ¡ˆç¢ºå¯¦å¯ä»¥å®Œç¾è§£æ±ºå¤šå·¥å…·åŒæ­¥å•é¡Œï¼

  âœ… æŠ€è¡“å¯è¡Œæ€§ï¼š95%

  - MCPå”è­°å·²æˆç†Ÿï¼Œä¸»æµå·¥å…·æ”¯æ´
  - Ollama 2025å¹´æ€§èƒ½å¤§å¹…æå‡
  - æ¶æ§‹è¨­è¨ˆåˆç†ï¼Œç„¡æŠ€è¡“éšœç¤™

  âœ… å•†æ¥­åƒ¹å€¼ï¼šæ¥µé«˜

  - è§£æ±ºçœŸå¯¦ç—›é»ï¼ˆå¤šå·¥å…·åˆ‡æ›ã€æå•ç²¾æº–åº¦ï¼‰
  - ç¨ç‰¹çš„éš±ç§ä¿è­·å„ªå‹¢ï¼ˆæœ¬åœ°Ollamaï¼‰
  - é›¶å» å•†ç¶å®šï¼Œç”¨æˆ¶è‡ªç”±åº¦é«˜

  âœ… å¯¦æ–½é›£åº¦ï¼šä¸­ç­‰

  - éœ€è¦æ•´åˆå¤šå€‹é–‹æºçµ„ä»¶
  - éœ€è¦æ·±åº¦ç†è§£MCPå”è­°
  - éœ€è¦å„ªåŒ–Ollamaæ¨¡å‹é¸æ“‡

  ğŸ¯ æœ€å¤§å„ªå‹¢ï¼šé–‹å‰µæ€§

  é€™å€‹æ–¹æ¡ˆå°‡æ˜¯é¦–å€‹å¯¦ç¾AI codingå·¥å…·å®Œå…¨çµ±ä¸€çš„è§£æ±ºæ–¹æ¡ˆï¼ŒåŒæ™‚è§£æ±ºäº†ï¼š
  1. å¤šå·¥å…·åŒæ­¥å•é¡Œ â†’ MCPçµ±ä¸€å”è­°
  2. æå•ç²¾æº–åº¦å•é¡Œ â†’ Ollamaæœ¬åœ°å„ªåŒ–
  3. éš±ç§å®‰å…¨å•é¡Œ â†’ æœ¬åœ°è™•ç†
  4. å» å•†ç¶å®šå•é¡Œ â†’ é–‹æ”¾æ¨™æº–